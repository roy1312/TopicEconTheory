{
 "metadata": {
  "name": "",
  "signature": "sha256:afaa8d5843d2829f1c3c7df7c5a33fda8f789dd5184a96930174278cf2449fbe"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "from itertools import product\n",
      "import quantecon as qe"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#parameters\n",
      "beta = 0.5\n",
      "delta = 0.9\n",
      "B = 10\n",
      "M = 5"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#define the utility under each state and action, set utility of unfeasible action to -inf\n",
      "r = np.zeros((B + M + 1, M + 1), dtype = float)\n",
      "\n",
      "for m, n in product(range(B+M+1), range(M+1)):\n",
      "    if n in range(min(m, M) + 1):\n",
      "        r[m, n] = (m - n) ** beta\n",
      "    else:\n",
      "        r[m,n ] = -np.inf\n",
      "np.set_printoptions(precision=4, threshold=None, edgeitems=8, linewidth=150, suppress=None, nanstr=None, infstr=None, formatter=None)\n",
      "print r"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[ 0.        -inf    -inf    -inf    -inf    -inf]\n",
        " [ 1.      0.        -inf    -inf    -inf    -inf]\n",
        " [ 1.4142  1.      0.        -inf    -inf    -inf]\n",
        " [ 1.7321  1.4142  1.      0.        -inf    -inf]\n",
        " [ 2.      1.7321  1.4142  1.      0.        -inf]\n",
        " [ 2.2361  2.      1.7321  1.4142  1.      0.    ]\n",
        " [ 2.4495  2.2361  2.      1.7321  1.4142  1.    ]\n",
        " [ 2.6458  2.4495  2.2361  2.      1.7321  1.4142]\n",
        " [ 2.8284  2.6458  2.4495  2.2361  2.      1.7321]\n",
        " [ 3.      2.8284  2.6458  2.4495  2.2361  2.    ]\n",
        " [ 3.1623  3.      2.8284  2.6458  2.4495  2.2361]\n",
        " [ 3.3166  3.1623  3.      2.8284  2.6458  2.4495]\n",
        " [ 3.4641  3.3166  3.1623  3.      2.8284  2.6458]\n",
        " [ 3.6056  3.4641  3.3166  3.1623  3.      2.8284]\n",
        " [ 3.7417  3.6056  3.4641  3.3166  3.1623  3.    ]\n",
        " [ 3.873   3.7417  3.6056  3.4641  3.3166  3.1623]]\n"
       ]
      }
     ],
     "prompt_number": 67
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#define the 3d array Q, first dimension state, second dimension action, third dimension  probability of next state\n",
      "Q = np.zeros((B + M + 1,M + 1,B +M +1), dtype = float)\n",
      "\n",
      "for m, n, k in product(range(B+M+1), range(M+1), range(B+M+1)):\n",
      "    if k in range(n, n + B + 1):\n",
      "        Q[m, n, k] = 1.0 / (B + 1)\n",
      "    else:\n",
      "        Q[m, n, k] = 0\n",
      "print Q[0,:,:] #result is  the same for each state"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[ 0.0909  0.0909  0.0909  0.0909  0.0909  0.0909  0.0909  0.0909  0.0909  0.0909  0.0909  0.      0.      0.      0.      0.    ]\n",
        " [ 0.      0.0909  0.0909  0.0909  0.0909  0.0909  0.0909  0.0909  0.0909  0.0909  0.0909  0.0909  0.      0.      0.      0.    ]\n",
        " [ 0.      0.      0.0909  0.0909  0.0909  0.0909  0.0909  0.0909  0.0909  0.0909  0.0909  0.0909  0.0909  0.      0.      0.    ]\n",
        " [ 0.      0.      0.      0.0909  0.0909  0.0909  0.0909  0.0909  0.0909  0.0909  0.0909  0.0909  0.0909  0.0909  0.      0.    ]\n",
        " [ 0.      0.      0.      0.      0.0909  0.0909  0.0909  0.0909  0.0909  0.0909  0.0909  0.0909  0.0909  0.0909  0.0909  0.    ]\n",
        " [ 0.      0.      0.      0.      0.      0.0909  0.0909  0.0909  0.0909  0.0909  0.0909  0.0909  0.0909  0.0909  0.0909  0.0909]]\n"
       ]
      }
     ],
     "prompt_number": 68
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 68
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#implement above algorithm in a class\n",
      "class MDP:\n",
      "    def __init__(self, delta, r, Q):\n",
      "        self.discount = delta\n",
      "        self.utility = np.array(r)\n",
      "        self.transition_matrix = np.array(Q)\n",
      "        \n",
      "        \n",
      "        \n",
      "    def Bellmanop(self, w): \n",
      "        \n",
      "        value = self.utility + delta * self.transition_matrix.dot(w)\n",
      "        Bw = value.max(axis = 1)\n",
      "        optimal_decision = value.argmax(axis = 1)\n",
      "\n",
      "        return Bw, optimal_decision\n",
      "    \n",
      "    def value_iteration(self,tol = 10 ** -7, max_iter = 10000):\n",
      "        w = self.utility[:,0] #initial value\n",
      "\n",
      "        cnt = 0\n",
      "        record_loop = []\n",
      "        for i in range(max_iter):\n",
      "            Bw, optimal_decision = self.Bellmanop(w)\n",
      "            if cnt < 10:\n",
      "                print optimal_decision \n",
      "            if max(abs(Bw[i] - w[i]) for i in range(len(w))) < tol:\n",
      "                print 'Loop ends after %d loops' %cnt\n",
      "                P = np.array(list(self.transition_matrix[x, optimal_decision[x], :] for x in range(len(self.transition_matrix[0,0,:]))))\n",
      "                return Bw, optimal_decision, P, record_loop\n",
      "            else:\n",
      "                record_loop.append(w)\n",
      "                w = Bw\n",
      "\n",
      "            cnt += 1\n",
      "            if cnt == max_iter:\n",
      "                print 'maximum loop'\n",
      "                P = np.array(list(self.transition_matrix[x, optimal_decision[x], :] for x in range(len(self.transition_matrix[0,0,:]))))\n",
      "                return Bw, optimal_decision, P, record_loop\n",
      "    \n",
      "    def policy_iteration(self, method,T = 10, max_iter = 10000, ):\n",
      "        S, G = self.utility.shape[0], self.utility.shape[1]\n",
      "        sigma = [0] * S #initial policy\n",
      "        v_sigma = [0] * S\n",
      "        cnt = 0\n",
      "        \n",
      "        for j in range(max_iter):\n",
      "            cnt += 1\n",
      "            #evaluate the policy\n",
      "            Q_sigma = []\n",
      "            k = 0\n",
      "            \n",
      "            for eachpolicy in sigma:\n",
      "                Q_sigma.append(self.transition_matrix[k, eachpolicy, :])\n",
      "                k += 1\n",
      "            Q_sigma = np.array(Q_sigma)\n",
      "            r_sigma = np.take(r, list(i * G + sigma[i] for i in range(S)))\n",
      "            \n",
      "            if method == 'exact':\n",
      "                coefficient = np.identity(S, dtype=float) - delta * Q_sigma\n",
      "                v_sigma = np.linalg.solve(coefficient, r_sigma)\n",
      "            else:\n",
      "                if T == 1:\n",
      "                    v_sigma = r_sigma + delta * Q_sigma.dot(v_sigma)\n",
      "                else:\n",
      "                    v_sigma = sum(delta**t * np.linalg.matrix_power(Q_sigma, t).dot(r_sigma) for t in range(T))\\\n",
      "                    + delta**T * np.linalg.matrix_power(Q_sigma, T).dot(v_sigma)\n",
      "\n",
      "                \n",
      "            #policy improvement\n",
      "            v_sigma1, sigma1 = self.Bellmanop(v_sigma)\n",
      "            \n",
      "            #print sigma\n",
      "            #print sigma1\n",
      "            print v_sigma\n",
      "\n",
      "            if (sigma1 == sigma).all():\n",
      "                print 'Loop ends in %d loops' %cnt\n",
      "                return sigma1, v_sigma1\n",
      "            else:\n",
      "                sigma = sigma1\n",
      "                #v_sigma = v_sigma1\n",
      "            if cnt == max_iter:\n",
      "                print 'maximum loop'\n",
      "                return sigma1, v_sigma1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 296
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dynamic = MDP(delta, r, Q)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 297
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Bw1, optimal_decision1, P1, record_loop1 = dynamic.value_iteration()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[0 0 0 0 1 1 1 1 2 2 2 3 3 4 4 4]\n",
        "[0 0 0 0 1 1 1 2 2 3 3 4 4 5 5 5]\n",
        "[0 0 0 0 1 1 1 2 2 3 3 4 4 5 5 5]\n",
        "[0 0 0 0 1 1 1 2 2 3 3 4 4 5 5 5]\n",
        "[0 0 0 0 1 1 1 2 2 3 3 4 4 5 5 5]\n",
        "[0 0 0 0 1 1 1 2 2 3 3 4 5 5 5 5]\n",
        "[0 0 0 0 1 1 1 2 2 3 3 4 5 5 5 5]\n",
        "[0 0 0 0 1 1 1 2 2 3 3 4 5 5 5 5]\n",
        "[0 0 0 0 1 1 1 2 2 3 3 4 5 5 5 5]\n",
        "[0 0 0 0 1 1 1 2 2 3 3 4 5 5 5 5]\n",
        "Loop ends after 160 loops\n"
       ]
      }
     ],
     "prompt_number": 298
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print optimal_decision1\n",
      "print Bw1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[0 0 0 0 1 1 1 2 2 3 3 4 5 5 5 5]\n",
        "[ 19.0174  20.0174  20.4316  20.7495  21.0408  21.3087  21.5448  21.7693  21.9827  22.1882  22.3845  22.5781  22.7611  22.9438  23.1153  23.2776]\n"
       ]
      }
     ],
     "prompt_number": 282
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Sigma1, V_sigma1 = dynamic.policy_iteration('exact')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[ 18.3831  19.3831  19.7974  20.1152  20.3831  20.6192  20.8326  21.0289  21.2116  21.3831  21.5454  21.6998  21.8472  21.9887  22.1248  22.2561]\n",
        "[ 18.9691  19.9691  20.3833  20.7011  20.9911  21.2591  21.4951  21.7086  21.9308  22.1271  22.3097  22.5137  22.6853  22.8766  23.0389  23.1932]\n",
        "[ 19.0173  20.0173  20.4315  20.7493  21.0407  21.3086  21.5447  21.7691  21.9825  22.1881  22.3843  22.5779  22.7606  22.9436  23.1152  23.2774]\n",
        "[ 19.0174  20.0174  20.4316  20.7495  21.0408  21.3087  21.5448  21.7693  21.9827  22.1882  22.3845  22.5781  22.7611  22.9438  23.1153  23.2776]\n",
        "Loop ends in 4 loops\n"
       ]
      }
     ],
     "prompt_number": 283
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print Sigma1\n",
      "print V_sigma1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[0 0 0 0 1 1 1 2 2 3 3 4 5 5 5 5]\n",
        "[ 19.0174  20.0174  20.4316  20.7495  21.0408  21.3087  21.5448  21.7693  21.9827  22.1882  22.3845  22.5781  22.7611  22.9438  23.1153  23.2776]\n"
       ]
      }
     ],
     "prompt_number": 284
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Sigma2, V_sigma2 = dynamic.policy_iteration('modified')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[ 11.2611  12.2611  12.6753  12.9932  13.2611  13.4972  13.7106  13.9069  14.0896  14.2611  14.4234  14.5778  14.7252  14.8667  15.0028  15.1341]\n",
        "[ 16.249   17.249   17.6632  17.9811  18.2711  18.539   18.7751  18.9885  19.2108  19.407   19.5897  19.7937  19.9653  20.1565  20.3188  20.4732]\n",
        "[ 18.0489  19.0489  19.4631  19.7809  20.0723  20.3402  20.5763  20.8007  21.0141  21.2197  21.4159  21.6095  21.7922  21.9752  22.1468  22.309 ]\n",
        "[ 18.6797  19.6797  20.0939  20.4117  20.7031  20.971   21.2071  21.4316  21.645   21.8505  22.0468  22.2404  22.4234  22.606   22.7776  22.9399]\n",
        "Loop ends in 4 loops\n"
       ]
      }
     ],
     "prompt_number": 285
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print Sigma2\n",
      "print V_sigma2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[0 0 0 0 1 1 1 2 2 3 3 4 5 5 5 5]\n",
        "[ 18.7135  19.7135  20.1277  20.4455  20.7368  21.0048  21.2409  21.4653  21.6788  21.8843  22.0806  22.2741  22.4571  22.6398  22.8114  22.9737]\n"
       ]
      }
     ],
     "prompt_number": 286
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Sigma3, V_sigma3 = dynamic.policy_iteration('modified', T = 1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[ 0.      1.      1.4142  1.7321  2.      2.2361  2.4495  2.6458  2.8284  3.      3.1623  3.3166  3.4641  3.6056  3.7417  3.873 ]\n",
        "[ 1.8383  2.8383  3.2525  3.5704  3.8417  4.1097  4.3457  4.5592  4.7608  4.957   5.1397  5.319   5.4906  5.655   5.8173  5.9716]\n",
        "[ 3.5356  4.5356  4.9499  5.2677  5.5525  5.8204  6.0565  6.2735  6.4869  6.6835  6.8797  7.0636  7.2463  7.4205  7.5921  7.7544]\n",
        "Loop ends in 3 loops\n"
       ]
      }
     ],
     "prompt_number": 287
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print Sigma3\n",
      "print V_sigma3"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[0 0 0 0 1 1 1 2 2 3 3 4 4 5 5 5]\n",
        "[ 5.0761  6.0761  6.4904  6.8082  7.0968  7.3648  7.6009  7.8226  8.0361  8.2382  8.4345  8.6247  8.8073  8.9875  9.1591  9.3213]\n"
       ]
      }
     ],
     "prompt_number": 288
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tests, testv = dynamic.Bellmanop(V_sigma3)\n",
      "print tests\n",
      "print testv"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[  6.4673   7.4673   7.8815   8.1993   8.4897   8.7576   8.9937   9.2172   9.4306   9.6349   9.8312  10.0235  10.2062  10.3882  10.5597  10.722 ]\n",
        "[0 0 0 0 1 1 1 2 2 3 3 4 4 5 5 5]\n"
       ]
      }
     ],
     "prompt_number": 289
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "It seems that optimal policy 'temporally' converges to Sigma3 so loop stopped;\n",
      "We can also see this from previous value iteration results"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}